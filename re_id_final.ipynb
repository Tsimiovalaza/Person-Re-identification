{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "re_id_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y0uO8CmPzXYu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce01a788e81a4dabb4a36f74d1bffc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a8afec3d54a49f48f41dc6578fb89f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e79f939fd3a7487c9c85a44d588779f6",
              "IPY_MODEL_d57670bad7be4795be29899fb154c620"
            ]
          }
        },
        "7a8afec3d54a49f48f41dc6578fb89f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e79f939fd3a7487c9c85a44d588779f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef093fee0af74c86a048604e482d42d6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_216580e2054f4516be093fa467ee82d5"
          }
        },
        "d57670bad7be4795be29899fb154c620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fda925412fdc48da9d2c8a00610aa656",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:54&lt;00:00, 1.89MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f17eeb174bb04023b151b348cfc21b4e"
          }
        },
        "ef093fee0af74c86a048604e482d42d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "216580e2054f4516be093fa467ee82d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda925412fdc48da9d2c8a00610aa656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f17eeb174bb04023b151b348cfc21b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phfq9hyw004e"
      },
      "source": [
        "# importing libraries and defining directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOZsW6sIsrDR"
      },
      "source": [
        "Importing libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw66P9I-sx32"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils,models\n",
        "from torchvision import transforms as T\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yxrU5cBSqWD",
        "outputId": "fa46f7e0-6f64-45af-b864-6509e6bcc747"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ho0UmQtAsh"
      },
      "source": [
        "defining the directories\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMFAzXfUtGEm"
      },
      "source": [
        "test_dir=\"/content/drive/MyDrive/projet deep learning/test\"\n",
        "queries_dir=\"/content/drive/MyDrive/projet deep learning/queries\"\n",
        "train_dir=\"/content/drive/MyDrive/projet deep learning/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIMLNNAhzrmy"
      },
      "source": [
        "# Model functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whsNXBguEKZH"
      },
      "source": [
        "class model_ft(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(model_ft, self).__init__()\n",
        "    model_resnet = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model_resnet.fc.in_features\n",
        "    model_resnet.fc = torch.nn.Sequential()\n",
        "    self.model_resnet=model_resnet\n",
        "    self.fc=torch.nn.Linear(num_ftrs,751)\n",
        "  def forward(self, x1):\n",
        "    x1 = self.model_resnet(x1)\n",
        "    x1= self.fc(x1)\n",
        "    return x1\n",
        "  def embed(self, x1):\n",
        "    x1 = self.model_resnet(x1)\n",
        "    return x1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bacTDyJLXz"
      },
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT52DYTPJ5MO"
      },
      "source": [
        "def get_optimizer(net, lr, wd, momentum):\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
        "  return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNoO6LBCzmD3"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0E-Vr7utfO1"
      },
      "source": [
        "organising train data in dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7CT7H5Ot3V0"
      },
      "source": [
        "d_train=dict()\n",
        "for filename in os.listdir(train_dir):\n",
        "      id_img=int(filename.split(\"_\")[0])\n",
        "      if id_img in d_train.keys():\n",
        "        d_train[id_img].append(filename)\n",
        "      else:\n",
        "        d_train[id_img]=[filename]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5IWb03dt4F6"
      },
      "source": [
        "creating a training list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ndgbxct6io"
      },
      "source": [
        "keys_list=np.array(list(d_train.keys()))\n",
        "full_train_list=[]\n",
        "for i in range(len(keys_list)):\n",
        "  for img in d_train[keys_list[i]]:\n",
        "    ele=[img , i]\n",
        "    full_train_list.append(ele)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZSQRZlwup3V"
      },
      "source": [
        "function to create the dataset and get the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgYb_HmG6aYh"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, l, root_dir, transform=None):\n",
        "        self.l =l\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.l)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path=os.path.join(self.root_dir,self.l[idx][0])\n",
        "        filename=self.l[idx][0]\n",
        "        label=self.l[idx][1]\n",
        "        img=cv2.imread(img_path)\n",
        "        img=cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return (img,label,filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTpyoDLOLC6i"
      },
      "source": [
        "def get_data(batch_size,l,root_dir):\n",
        "  transform = list()\n",
        "  transform.append(T.ToTensor())\n",
        "  transform.append(T.Resize((224,224)))\n",
        "  transform.append(T.RandomHorizontalFlip(p=0.4)) \n",
        "  transform.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))           \n",
        "  transform = T.Compose(transform)\n",
        "  full_training_data = MyDataset(l,root_dir, transform=transform)\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.7+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=1)\n",
        "  validation_loader=torch.utils.data.DataLoader(validation_data, batch_size, shuffle=True, num_workers=1)\n",
        "  return training_data, validation_data,train_loader,validation_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-2JXWdvF1t"
      },
      "source": [
        "the training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u75Lxti2J6It"
      },
      "source": [
        "def train(net,data_loader,optimizer,cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  \n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  for batch_idx, (anchors,labels,filename) in enumerate(data_loader):\n",
        "    # Load data into GPU\n",
        "    anchors = anchors.to(device)\n",
        "    labels=labels.to(device)\n",
        "    # Forward pass\n",
        "    anchors_out = net(anchors)\n",
        "    # Apply the loss\n",
        "    loss = cost_function(anchors_out,labels)\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "    # Reset the optimizer\n",
        "    optimizer.zero_grad()\n",
        "    samples+=anchors.shape[0]\n",
        "    cumulative_accuracy+=( (torch.argmax(anchors_out, dim=1)==labels)*1 ).sum()\n",
        "    # Better print something, no?\n",
        "    print(samples)\n",
        "    cumulative_loss += loss.item()\n",
        "  return cumulative_loss/samples,cumulative_accuracy/samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPwcSWVCvWIO"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsyyHAJvL0mw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "ce01a788e81a4dabb4a36f74d1bffc91",
            "7a8afec3d54a49f48f41dc6578fb89f6",
            "e79f939fd3a7487c9c85a44d588779f6",
            "d57670bad7be4795be29899fb154c620",
            "ef093fee0af74c86a048604e482d42d6",
            "216580e2054f4516be093fa467ee82d5",
            "fda925412fdc48da9d2c8a00610aa656",
            "f17eeb174bb04023b151b348cfc21b4e"
          ]
        },
        "outputId": "92836b6f-437f-4e4b-a5a9-2ac719b89077"
      },
      "source": [
        "batch_size=32\n",
        "device='cuda:0' \n",
        "learning_rate=0.0003\n",
        "weight_decay=0.000001\n",
        "momentum=0.9\n",
        "epochs=25\n",
        "training_data, validation_data,train_loader,validation_loader = get_data(batch_size,full_train_list,train_dir)\n",
        "net = model_ft().to(device)\n",
        "optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "cost_function = get_cost_function()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce01a788e81a4dabb4a36f74d1bffc91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102530333.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ioejBJK33MQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d05fa892-db54-4445-baf1-c6afdc4dbcdd"
      },
      "source": [
        "print('start training')\n",
        "accuracy_per_epoch=[]\n",
        "loss_per_epoch=[]\n",
        "for e in range(epochs):\n",
        "    train_loss,train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('train loss: ',train_loss)\n",
        "    print('train_accuracy: ',train_accuracy*100)\n",
        "    loss_per_epoch.append(train_loss)\n",
        "    accuracy_per_epoch.append(train_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "32.0\n",
            "64.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-89fcbcc601ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {:d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train loss: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-38ac9766c445>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, optimizer, cost_function, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Strictly needed if network contains layers which has different behaviours between train and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Load data into GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ThM37zi82BX"
      },
      "source": [
        "epochs=[i+1 for i in range(25)]\n",
        "plt.plot(epochs,accuracy_per_epoch)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_UrxxZD9ekN"
      },
      "source": [
        "plt.plot(epochs,loss_per_epoch)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tL0HvM9sig"
      },
      "source": [
        "def test(net, data_loader, cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets,filename) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "        \n",
        "      # Forward pass\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      # Apply the loss\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = outputs.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "      print(samples)\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W6SPcX6-BUq"
      },
      "source": [
        "val_loss,val_accuracy=test(net,validation_loader,cost_function)\n",
        "print(\"loss for validation: \",val_loss)\n",
        "print(\"accuracy for validation: \",val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvNOvKQwF7D"
      },
      "source": [
        "Saving the model after training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR1EybaLwIo0"
      },
      "source": [
        "torch.save(net.state_dict(), \"/content/drive/MyDrive/projet deep learning/person_reid_model_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0uO8CmPzXYu"
      },
      "source": [
        "# Testing Person re-id for the validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws_Ifg9zzEoE"
      },
      "source": [
        "loading our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pSvOOlVyN5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230b263f-d601-404c-9aae-e17d19f369b6"
      },
      "source": [
        "device='cuda:0' \n",
        "net = model_ft().to(device)\n",
        "net.load_state_dict(torch.load(\"/content/drive/MyDrive/projet deep learning/person_reid_model_2\"), strict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia7Q8qQ71F0G"
      },
      "source": [
        "class testing_Dataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, l, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.l =l\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.l)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path=os.path.join(self.root_dir,  self.l[idx])\n",
        "        img=cv2.imread(img_path)\n",
        "        img=cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uadNSsllwuRw"
      },
      "source": [
        "def get_test_data(batch_size,l,root_dir):\n",
        "  transform = list()\n",
        "  transform.append(T.ToTensor())\n",
        "  transform.append(T.Resize((224,224)))                             # converts Numpy to Pytorch Tensor\n",
        "  transform.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))                         \n",
        "     # Normalizes the Tensors \n",
        "  transform = T.Compose(transform)\n",
        "  data = testing_Dataset(l,root_dir, transform=transform)\n",
        "  data_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=False, num_workers=1)\n",
        "  return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIiPHjduxYFV"
      },
      "source": [
        "def image_embed(l,root_dir,net,device):\n",
        "  data_loader = get_test_data(1,l,root_dir)\n",
        "  img_embd_arr=np.zeros( ( len(l) , 2048) )\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx ,img in enumerate(data_loader):\n",
        "      input=img.to(device)\n",
        "      img_embd=net.embed(input)\n",
        "      img_embd=img_embd.cpu().detach().numpy()\n",
        "      img_embd_arr[batch_idx]=img_embd\n",
        "      if (batch_idx % 256 ==0) :\n",
        "        print(batch_idx)\n",
        "  return torch.tensor(img_embd_arr).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuaJli39x1HP"
      },
      "source": [
        "def predict(query_l,queries_dir,test_l,test_dir,net,device):\n",
        "  img_embd_query=image_embed(query_l,queries_dir,net,device)\n",
        "  print('query_embedding_finished')\n",
        "  img_embd_test=image_embed(test_l,test_dir,net,device)\n",
        "  print('test_embedding_finished')\n",
        "  cos=torch.nn.CosineSimilarity(dim=1)\n",
        "  d={ key:[] for key in query_l }\n",
        "  for j in range( len(query_l) ):\n",
        "      bo =np.array( cos(img_embd_query[j:j+1],img_embd_test) > 0.86 ) \n",
        "\n",
        "      d[ query_l[j] ].append(test_l[i])\n",
        "  return d,img_embd_query,img_embd_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNCuRPTyvE8x"
      },
      "source": [
        "from typing import Dict, Set, List\n",
        "def evaluate_map(predictions: Dict[str, List], ground_truth: Dict[str, Set]):\n",
        "        '''\n",
        "        Computes the mAP (https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173) of the predictions with respect to the given ground truth\n",
        "        In person reidentification mAP refers to the mean of the AP over all queries.\n",
        "        The AP for a query is the area under the precision-recall curve obtained from the list of predictions considering the\n",
        "        ground truth elements as positives and the other ones as negatives\n",
        "\n",
        "        :param predictions: dictionary from query filename to list of test image filenames associated with the query ordered\n",
        "                            from the most to the least confident prediction.\n",
        "                            Represents the predictions to be evaluated.\n",
        "        :param ground_truth: dictionary from query filename to set of test image filenames associated with the query\n",
        "                             Represents the ground truth on which to evaluate predictions.\n",
        "\n",
        "        :return:\n",
        "        '''\n",
        "\n",
        "        m_ap = 0.0\n",
        "        for current_ground_truth_query, current_ground_truth_query_set in ground_truth.items():\n",
        "\n",
        "            # No predictions were performed for the current query, AP = 0\n",
        "            if not current_ground_truth_query in predictions:\n",
        "                continue\n",
        "\n",
        "            current_ap = 0.0  # The area under the curve for the current sample\n",
        "            current_predictions_list = predictions[current_ground_truth_query]\n",
        "            if len(current_ground_truth_query_set)==0 :\n",
        "              continue\n",
        "            # Recall increments of this quantity each time a new correct prediction is encountered in the prediction list\n",
        "            delta_recall = 1.0 / len(current_ground_truth_query_set)\n",
        "\n",
        "            # Goes through the list of predictions\n",
        "            encountered_positives = 0\n",
        "            for idx, current_prediction in enumerate(current_predictions_list):\n",
        "                # Each time a positive is encountered, compute the current precition and the area under the curve\n",
        "                # since the last positive\n",
        "                if current_prediction in current_ground_truth_query_set:\n",
        "                    encountered_positives += 1\n",
        "                    current_precision = encountered_positives / (idx + 1)\n",
        "                    current_ap += current_precision * delta_recall\n",
        "\n",
        "            m_ap += current_ap\n",
        "\n",
        "        # Compute mean over all queries\n",
        "        m_ap /= len(ground_truth)\n",
        "\n",
        "        return m_ap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb7jTuB80ST2"
      },
      "source": [
        "Creating query and test list from the training directory to evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci2uhuA60Lp8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5e9f55b7-ec79-4a74-d804-8e70000c52f8"
      },
      "source": [
        "train_query_list=[]\n",
        "train_test_list=[]\n",
        "query_ids_list=[]\n",
        "d_test_truth={}\n",
        "d_ids={}\n",
        "i=1\n",
        "for img,id_img,filename in training_data:\n",
        "      if id_img not in query_ids_list:\n",
        "        query_ids_list.append(id_img)\n",
        "        train_query_list.append(filename)\n",
        "        d_ids[id_img]=filename\n",
        "        d_test_truth[d_ids[id_img]]=set()\n",
        "      else:\n",
        "        train_test_list.append(filename)\n",
        "        d_test_truth[d_ids[id_img]].add(filename)\n",
        "      i+=1\n",
        "      if (i%256==0):\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0c805622a331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mid_img\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_ids_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mquery_ids_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-78e13d305068>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uaW4AIM1jIH"
      },
      "source": [
        "Making the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI_JEKscz6cU"
      },
      "source": [
        "d_pred_train,img_embd_query,img_embd_test=predict(train_query_list,train_dir,train_test_list,train_dir,net,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFOUX7nl4y32"
      },
      "source": [
        "evaluating map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdjO9B0avLRk"
      },
      "source": [
        "evaluate_map(d_pred_train,d_test_truth)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXwFkvGM9yAI"
      },
      "source": [
        "val_query_list=[]\n",
        "val_test_list=[]\n",
        "query_ids_list=[]\n",
        "d_test_truth={}\n",
        "d_ids={}\n",
        "i=1\n",
        "for img,id_img,filename in validation_data:\n",
        "      if id_img not in query_ids_list:\n",
        "        query_ids_list.append(id_img)\n",
        "        val_query_list.append(filename)\n",
        "        d_ids[id_img]=filename\n",
        "        d_test_truth[d_ids[id_img]]=set()\n",
        "      else:\n",
        "        val_test_list.append(filename)\n",
        "        d_test_truth[d_ids[id_img]].add(filename)\n",
        "      i+=1\n",
        "      if (i%256==0):\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E_IezKW_DZF"
      },
      "source": [
        "d_pred_val,img_embd_query,img_embd_test=predict(val_query_list,train_dir,val_test_list,train_dir,net,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAyMBMad_I0h"
      },
      "source": [
        "evaluate_map(d_pred_val,d_test_truth)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSxondnu6FXr"
      },
      "source": [
        "# Making the predictions for test and query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4SDuSlV614I"
      },
      "source": [
        "creating test and query list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1HCN47w6nUA"
      },
      "source": [
        "query_test=[]\n",
        "val_test=[]\n",
        "for filename in os.listdir(test_dir):\n",
        "    val_test.append(filename)\n",
        "for filename in os.listdir(queries_dir):\n",
        "    query_test.append(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHVyPXB7FeA"
      },
      "source": [
        "making the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmloNjd7Esj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e377cac4-66c0-4530-d9ef-a3bbf4130ede"
      },
      "source": [
        "d_pred_val,img_embd_query,img_embd_test=predict(query_test,queries_dir,val_test,test_dir,net,device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "256\n",
            "512\n",
            "768\n",
            "1024\n",
            "1280\n",
            "1536\n",
            "1792\n",
            "2048\n",
            "query_embedding_finished\n",
            "0\n",
            "256\n",
            "512\n",
            "768\n",
            "1024\n",
            "1280\n",
            "1536\n",
            "1792\n",
            "2048\n",
            "2304\n",
            "2560\n",
            "2816\n",
            "3072\n",
            "3328\n",
            "3584\n",
            "3840\n",
            "4096\n",
            "4352\n",
            "4608\n",
            "4864\n",
            "5120\n",
            "5376\n",
            "5632\n",
            "5888\n",
            "6144\n",
            "6400\n",
            "6656\n",
            "6912\n",
            "7168\n",
            "7424\n",
            "7680\n",
            "7936\n",
            "8192\n",
            "8448\n",
            "8704\n",
            "8960\n",
            "9216\n",
            "9472\n",
            "9728\n",
            "9984\n",
            "10240\n",
            "10496\n",
            "10752\n",
            "11008\n",
            "11264\n",
            "11520\n",
            "11776\n",
            "12032\n",
            "12288\n",
            "12544\n",
            "12800\n",
            "13056\n",
            "13312\n",
            "13568\n",
            "13824\n",
            "14080\n",
            "14336\n",
            "14592\n",
            "14848\n",
            "15104\n",
            "15360\n",
            "15616\n",
            "15872\n",
            "16128\n",
            "16384\n",
            "16640\n",
            "16896\n",
            "17152\n",
            "17408\n",
            "17664\n",
            "17920\n",
            "18176\n",
            "18432\n",
            "18688\n",
            "18944\n",
            "19200\n",
            "19456\n",
            "test_embedding_finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEfNCJudbo4W"
      },
      "source": [
        "writing in the prediction in a file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J7BwFAzbt-Z"
      },
      "source": [
        "f = open(\"/content/drive/MyDrive/projet deep learning/reid_test.txt\", \"w\")\n",
        "for key in d_pred_val.keys():\n",
        "    s=', '.join(d_pred_val[key])\n",
        "    f.write(str(key)+': '+s+'\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}